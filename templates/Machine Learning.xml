<templateSet group="Machine Learning">
  <template name="MlGradientBoostingRegressorTrain" value="import pandas as pd&#10;from sklearn import ensemble&#10;from sklearn.model_selection import train_test_split&#10;from sklearn.externals import joblib&#10;from sklearn.metrics import mean_absolute_error&#10;&#10;data_table = pd.read_csv('ml_house_data_set.csv')&#10;&#10;&#10;del data_table['house_number']&#10;del data_table['unit_number']&#10;del data_table['street_name']&#10;del data_table['zip_code']&#10;&#10;# Replace categorical data with one-hop encoded data&#10;features_df = pd.get_dummies(data_table, columns=['garage_type', 'city'])&#10;&#10;del features_df['sale_price']&#10;&#10;X = features_df.as_matrix()&#10;y = data_table['sale_price'].as_matrix()&#10;&#10;X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)&#10;&#10;# this combines a bunch of decision trees and each tree improves the other&#10;model = ensemble.GradientBoostingRegressor(&#10;    n_estimators=1000, # how many decision trees&#10;    learning_rate=0.1, # how much one tree influences the other&#10;    max_depth=6, # layers deep&#10;    min_samples_leaf=9, # needs to appear to make a difference&#10;    max_features=0.1,&#10;    loss='huber'&#10;)&#10;&#10;model.fit(X_train, y_train)&#10;&#10;joblib.dump(model, 'trained_house_classifier_model.pkl')&#10;&#10;mse = mean_absolute_error(y_train, model.predict(X_train))&#10;print('Training Set Mean Absolute Error: %.4f' % mse)&#10;&#10;mse = mean_absolute_error(y_test, model.predict(X_test))&#10;print('Test Set Mean Absolute Error: %.4f' % mse)&#10;" description="Snipped for GBR model. This will create a pkl file." toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
      <option name="Python_Class" value="false" />
    </context>
  </template>
  <template name="MlGradientBoostingRegressorFeatureSelector" value="import numpy as np&#10;from sklearn.externals import joblib&#10;&#10;feature_labels = np.array(['year_built', 'stories', 'num_bedrooms', 'full_bathrooms', 'half_bathrooms', 'livable_sqft', 'total_sqft', 'garage_sqft', 'carport_sqft', 'has_fireplace', 'has_pool', 'has_central_heating', 'has_central_cooling', 'garage_type_attached', 'garage_type_detached', 'garage_type_none', 'city_Amystad', 'city_Brownport', 'city_Chadstad', 'city_Clarkberg', 'city_Coletown', 'city_Davidfort', 'city_Davidtown', 'city_East Amychester', 'city_East Janiceville', 'city_East Justin', 'city_East Lucas', 'city_Fosterberg', 'city_Hallfort', 'city_Jeffreyhaven', 'city_Jenniferberg', 'city_Joshuafurt', 'city_Julieberg', 'city_Justinport', 'city_Lake Carolyn', 'city_Lake Christinaport', 'city_Lake Dariusborough', 'city_Lake Jack', 'city_Lake Jennifer', 'city_Leahview', 'city_Lewishaven', 'city_Martinezfort', 'city_Morrisport', 'city_New Michele', 'city_New Robinton', 'city_North Erinville', 'city_Port Adamtown', 'city_Port Andrealand', 'city_Port Daniel', 'city_Port Jonathanborough', 'city_Richardport', 'city_Rickytown', 'city_Scottberg', 'city_South Anthony', 'city_South Stevenfurt', 'city_Toddshire', 'city_Wendybury', 'city_West Ann', 'city_West Brittanyview', 'city_West Gerald', 'city_West Gregoryview', 'city_West Lydia', 'city_West Terrence'])&#10;&#10;model = joblib.load('trained_house_classifier_model.pkl')&#10;&#10;importance = model.feature_importances_&#10;&#10;feature_indexes_by_importance = importance.argsort()&#10;&#10;for index in feature_indexes_by_importance:&#10;    print('{} - {:.2f}%'.format(feature_labels[index], (importance[index] * 100.0)))&#10;" description="Prints the percentage of how often each feature was called in this model." toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
      <option name="Python_Class" value="false" />
    </context>
  </template>
  <template name="MlGridSearch" value="import pandas as pd&#10;from sklearn import ensemble&#10;from sklearn.model_selection import GridSearchCV&#10;from sklearn.model_selection import train_test_split&#10;&#10;data_table = pd.read_csv('ml_house_data_set.csv')&#10;&#10;&#10;del data_table['house_number']&#10;del data_table['unit_number']&#10;del data_table['street_name']&#10;del data_table['zip_code']&#10;&#10;features_df = pd.get_dummies(data_table, columns=['garage_type', 'city'])&#10;&#10;del features_df['sale_price']&#10;&#10;X = features_df.as_matrix()&#10;y = data_table['sale_price'].as_matrix()&#10;&#10;X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)&#10;&#10;model = ensemble.GradientBoostingRegressor()&#10;&#10;# hipper-parameters&#10;param_grid = {&#10;    'n_estimators': [500, 1000],  # how many decision trees&#10;    'learning_rate': [0.1, 0.01],  # how much one tree influences the other&#10;    'max_depth': [4, 6],  # layers deep&#10;    'min_samples_leaf': [3, 9],  # needs to appear to make a difference&#10;    'max_features': [1.0, 0.1],&#10;    'loss': ['ls', 'lad', 'huber']&#10;}&#10;&#10;gs_cv = GridSearchCV(model, param_grid, n_jobs=4)&#10;&#10;gs_cv.fit(X_train, y_train)&#10;&#10;print(gs_cv.best_params_)&#10;# {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'max_features': 0.1, 'min_samples_leaf': 9, 'n_estimators': 1000}&#10;" description="GridSearch for a model. Finds what hipper-parameters are best" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
      <option name="Python_Class" value="false" />
    </context>
  </template>
  <template name="MlGradientBoostingRegressorPredict" value="from sklearn.externals import joblib&#10;&#10;model = joblib.load('trained_house_classifier_model.pkl')&#10;&#10;house_to_value = [&#10;    # House features&#10;    1973,  # year_built&#10;    1,  # stories&#10;    4,  # num_bedrooms&#10;    3,  # full_bathrooms&#10;    0,  # half_bathrooms&#10;    2200,  # livable_sqft&#10;    2350,  # total_sqft&#10;    400,  # garage_sqft&#10;    0,  # carport_sqft&#10;    True,  # has_fireplace&#10;    False,  # has_pool&#10;    True,  # has_central_heating&#10;    True,  # has_central_cooling&#10;&#10;    # Garage type: Choose only one&#10;    1,  # attached&#10;    0,  # detached&#10;    0,  # none&#10;&#10;    # City: Choose only one&#10;    0,  # Amystad&#10;    1,  # Brownport&#10;    0,  # Chadstad&#10;    0,  # Clarkberg&#10;    0,  # Coletown&#10;    0,  # Davidfort&#10;    0,  # Davidtown&#10;    0,  # East Amychester&#10;    0,  # East Janiceville&#10;    0,  # East Justin&#10;    0,  # East Lucas&#10;    0,  # Fosterberg&#10;    0,  # Hallfort&#10;    0,  # Jeffreyhaven&#10;    0,  # Jenniferberg&#10;    0,  # Joshuafurt&#10;    0,  # Julieberg&#10;    0,  # Justinport&#10;    0,  # Lake Carolyn&#10;    0,  # Lake Christinaport&#10;    0,  # Lake Dariusborough&#10;    0,  # Lake Jack&#10;    0,  # Lake Jennifer&#10;    0,  # Leahview&#10;    0,  # Lewishaven&#10;    0,  # Martinezfort&#10;    0,  # Morrisport&#10;    0,  # New Michele&#10;    0,  # New Robinton&#10;    0,  # North Erinville&#10;    0,  # Port Adamtown&#10;    0,  # Port Andrealand&#10;    0,  # Port Daniel&#10;    0,  # Port Jonathanborough&#10;    0,  # Richardport&#10;    0,  # Rickytown&#10;    0,  # Scottberg&#10;    0,  # South Anthony&#10;    0,  # South Stevenfurt&#10;    0,  # Toddshire&#10;    0,  # Wendybury&#10;    0,  # West Ann&#10;    0,  # West Brittanyview&#10;    0,  # West Gerald&#10;    0,  # West Gregoryview&#10;    0,  # West Lydia&#10;    0  # West Terrence&#10;]&#10;&#10;homes_to_value = [&#10;    house_to_value&#10;]&#10;&#10;predicted_home_values = model.predict(homes_to_value)&#10;&#10;predicted_value = predicted_home_values[0]&#10;&#10;print('This house has an estimated value of ${:,.2f}'.format(predicted_value))&#10;&#10;" description="Predicts using model" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
</templateSet>